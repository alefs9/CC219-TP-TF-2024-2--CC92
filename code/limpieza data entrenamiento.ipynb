{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3d22cf",
   "metadata": {},
   "source": [
    "# Parte 3: Limpieza del texto para modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8261277",
   "metadata": {},
   "source": [
    "El preprocesamiento del texto es esencial para reducir el ruido y mejorar la calidad del aprendizaje automático. El objetivo de esta etapa es:\n",
    "\n",
    "- Eliminar palabras genéricas o irrelevantes\n",
    "- Reducir vocabulario redundante (palabras con frecuencia 1)\n",
    "- Filtrar tokens anómalos (muy largos o poco informativos)\n",
    "- Optimizar el corpus para enfoques como TF-IDF y embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56c6dd",
   "metadata": {},
   "source": [
    "### Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178a8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d75d2b",
   "metadata": {},
   "source": [
    "### Carga y Limpieza del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b59291e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_11604\\1043033834.py:2: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  data_limpia = pd.read_csv('C:\\CC219-TP-TF-2024-2--CC92\\data\\data_limpia.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (8469, 11)\n",
      "\n",
      "Primeras filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Age</th>\n",
       "      <th>Customer Gender</th>\n",
       "      <th>Product Purchased</th>\n",
       "      <th>Date of Purchase</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Status</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Channel</th>\n",
       "      <th>Hours_to_First_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>Other</td>\n",
       "      <td>GoPro Hero</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Social media</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>LG Smart TV</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>Other</td>\n",
       "      <td>Dell XPS</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>Microsoft Office</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>Billing inquiry</td>\n",
       "      <td>Account access</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Autodesk AutoCAD</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>Billing inquiry</td>\n",
       "      <td>Data loss</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Low</td>\n",
       "      <td>Email</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer Age Customer Gender Product Purchased Date of Purchase  \\\n",
       "0            32           Other        GoPro Hero       2021-03-22   \n",
       "1            42          Female       LG Smart TV       2021-05-22   \n",
       "2            48           Other          Dell XPS       2020-07-14   \n",
       "3            27          Female  Microsoft Office       2020-11-13   \n",
       "4            67          Female  Autodesk AutoCAD       2020-02-04   \n",
       "\n",
       "       Ticket Type            Ticket Subject  \\\n",
       "0  Technical issue             Product setup   \n",
       "1  Technical issue  Peripheral compatibility   \n",
       "2  Technical issue           Network problem   \n",
       "3  Billing inquiry            Account access   \n",
       "4  Billing inquiry                 Data loss   \n",
       "\n",
       "                                  Ticket Description  \\\n",
       "0  I'm having an issue with the {product_purchase...   \n",
       "1  I'm having an issue with the {product_purchase...   \n",
       "2  I'm facing a problem with my {product_purchase...   \n",
       "3  I'm having an issue with the {product_purchase...   \n",
       "4  I'm having an issue with the {product_purchase...   \n",
       "\n",
       "               Ticket Status Ticket Priority Ticket Channel  \\\n",
       "0  Pending Customer Response        Critical   Social media   \n",
       "1  Pending Customer Response        Critical           Chat   \n",
       "2                     Closed             Low   Social media   \n",
       "3                     Closed             Low   Social media   \n",
       "4                     Closed             Low          Email   \n",
       "\n",
       "   Hours_to_First_Response  \n",
       "0                      7.0  \n",
       "1                      6.0  \n",
       "2                      7.0  \n",
       "3                      6.0  \n",
       "4                     20.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset limpio\n",
    "data_limpia = pd.read_csv('C:\\CC219-TP-TF-2024-2--CC92\\data\\data_limpia.csv')\n",
    "\n",
    "# Revisar el dataset\n",
    "print(\"Dimensiones del dataset:\", data_limpia.shape)\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "data_limpia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5848512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variables objetivo\n",
    "# Se consideran \"urgentes\" los tickets con prioridad \"Critical\" o \"High\" (valor 1), el resto son \"no urgentes\" (valor 0)\n",
    "data_limpia[\"Urgency\"] = data_limpia[\"Ticket Priority\"].apply(lambda x: 1 if x in [\"Critical\", \"High\"] else 0)\n",
    "\n",
    "# Tickets con tiempo de respuesta igual o menor a 1 hora toman el valor de 1, el resto como 0\n",
    "data_limpia[\"Resolution_Time_Bin\"] = data_limpia[\"Hours_to_First_Response\"].apply(lambda x: 1 if x <= 1 else 0)\n",
    "\n",
    "# Filtrar columnas relevantes\n",
    "data_limpia = data_limpia[[\"Ticket Description\", \"Ticket Priority\", \"Ticket Channel\", \"Urgency\", \"Resolution_Time_Bin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f1efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urgencia:\n",
      "- No urgente (0): 4255 (50.24%)\n",
      "- Urgente (1): 4214 (49.76%)\n",
      "\n",
      "Tiempo de resolución:\n",
      "- Más de una hora (0): 8140 (96.12%)\n",
      "- Menos de una hora (1): 329 (3.88%)\n"
     ]
    }
   ],
   "source": [
    "# Verificación\n",
    "total = len(data_limpia)\n",
    "\n",
    "# Urgencia\n",
    "urg_counts = data_limpia[\"Urgency\"].value_counts()\n",
    "print(f\"Urgencia:\")\n",
    "print(f\"- No urgente (0): {urg_counts[0]} ({urg_counts[0] / total:.2%})\")\n",
    "print(f\"- Urgente (1): {urg_counts[1]} ({urg_counts[1] / total:.2%})\\n\")\n",
    "\n",
    "# Tiempo de resolución\n",
    "res_counts = data_limpia[\"Resolution_Time_Bin\"].value_counts()\n",
    "print(f\"Tiempo de resolución:\")\n",
    "print(f\"- Más de una hora (0): {res_counts[0]} ({res_counts[0] / total:.2%})\")\n",
    "print(f\"- Menos de una hora (1): {res_counts[1]} ({res_counts[1] / total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78db2c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Channel</th>\n",
       "      <th>Urgency</th>\n",
       "      <th>Resolution_Time_Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Social media</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Email</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Ticket Description Ticket Priority  \\\n",
       "0  I'm having an issue with the {product_purchase...        Critical   \n",
       "1  I'm having an issue with the {product_purchase...        Critical   \n",
       "2  I'm facing a problem with my {product_purchase...             Low   \n",
       "3  I'm having an issue with the {product_purchase...             Low   \n",
       "4  I'm having an issue with the {product_purchase...             Low   \n",
       "\n",
       "  Ticket Channel  Urgency  Resolution_Time_Bin  \n",
       "0   Social media        1                    0  \n",
       "1           Chat        1                    0  \n",
       "2   Social media        0                    0  \n",
       "3   Social media        0                    0  \n",
       "4          Email        0                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_limpia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93819ba",
   "metadata": {},
   "source": [
    "Se crean dos variables clave para entrenar los modelos de clasificación:\n",
    "- Urgency: marca los tickets como urgentes (1) si su prioridad es Critical o High, y como no urgentes (0) en otros casos.\n",
    "- Resolution_Time_Bin: indica si el ticket recibió una primera respuesta en menos de una hora (1) o no (0).\n",
    "\n",
    "Luego, se filtran las columnas más relevantes: la descripción del ticket, el canal por el que ingresó y las dos nuevas etiquetas objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e5c820",
   "metadata": {},
   "source": [
    "Estas variables son relevantes porque se relacionan directamente con los insights obtenidos:\n",
    "\n",
    "* **Urgency** permite identificar si un ticket es crítico o no según su prioridad. Esto es útil para entrenar modelos que ayuden a mejorar la **priorización automática de tickets urgentes** (Insight 1).\n",
    "\n",
    "* **Resolution\\_Time\\_Bin** indica si la primera respuesta fue rápida (menos de una hora). Al relacionarla con el canal de entrada, permite evaluar el **desempeño de los canales** y encontrar oportunidades de mejora (Insight 2).\n",
    "\n",
    "* **Ticket Description** proporciona el texto del problema, que puede contener patrones comunes relacionados con urgencia o demoras, ayudando a **detectar temas frecuentes y optimizar la respuesta** (Insight 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e7b77",
   "metadata": {},
   "source": [
    "### Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c264a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Limpieza de texto\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\{.*?\\}', '', text)                    # Eliminar placeholders como {product_purchased}\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                # Eliminar todo excepto letras y espacios\n",
    "    text = text.lower()                                    # Pasar todo a minúsculas\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)                # Eliminar palabras de 1 o 2 letras (como \"i\", \"as\", \"is\")\n",
    "    text = re.sub(r'\\s+', ' ', text)                       # Reemplazar múltiples espacios por uno solo\n",
    "    words = text.split()                                   # Divide el texto en palabras individuales\n",
    "    words = [w for w in words if w not in stop_words]      # Elimina stopwords\n",
    "    return ' '.join(words)                                 # Reconstruye el texto limpio como una sola cadena\n",
    "\n",
    "data_limpia[\"Ticket Description\"] = data_limpia[\"Ticket Description\"].apply(clean_text)\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "categorical_features = [\"Ticket Priority\", \"Ticket Channel\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Pipeline para vectorizar el texto con TF-IDF (limita a las 5000 palabras más relevantes y elimina stopwords adicionales)\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english'))])\n",
    "\n",
    "# Combinación de transformadores: texto (TF-IDF) + variables categóricas (one-hot)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf', text_transformer, \"Ticket Description\"),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1050bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del conjunto transformado: (8469, 5008)\n",
      "issue please assist worried issue might hardwarerelated might require repair replacement\n",
      "\n",
      "Categorías codificadas: ['Ticket Priority_Critical' 'Ticket Priority_High' 'Ticket Priority_Low']\n",
      "Palabras TF-IDF más comunes: ['ability' 'able' 'abovementioned' 'abovethen' 'abroad']\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el preprocesamiento a una muestra\n",
    "X_preprocessed = preprocessor.fit_transform(data_limpia)\n",
    "\n",
    "# Imprimir forma del resultado\n",
    "print(\"Forma del conjunto transformado:\", X_preprocessed.shape)\n",
    "\n",
    "# Verificar limpieza de texto\n",
    "print(data_limpia[\"Ticket Description\"].sample(1).values[0])\n",
    "\n",
    "# Verificar categorías detectadas\n",
    "ohe = preprocessor.named_transformers_['cat']['onehot']\n",
    "print(\"\\nCategorías codificadas:\", ohe.get_feature_names_out(categorical_features)[:3])\n",
    "\n",
    "# Verificar palabras clave extraídas del texto\n",
    "tfidf = preprocessor.named_transformers_['tfidf']['tfidf']\n",
    "print(\"Palabras TF-IDF más comunes:\", tfidf.get_feature_names_out()[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a6ce7",
   "metadata": {},
   "source": [
    "### Interpretación de la salida transformada\n",
    "\n",
    "- **Forma del conjunto transformado: (8469, 5008)**  \n",
    "  Esto indica que, después de aplicar la transformación de texto y la codificación de variables categóricas, contamos con un total de 8469 ejemplos (tickets) y 5008 características distintas por ejemplo. Estas características incluyen tanto las palabras relevantes del texto como las variables categóricas transformadas (como prioridad o canal del ticket).\n",
    "\n",
    "- **Ejemplo de texto limpio:**  \n",
    "  Se muestra un ejemplo del contenido de un ticket después de la limpieza. En esta etapa, se eliminaron caracteres especiales, palabras vacías (stopwords), y palabras poco informativas, dejando solo los términos relevantes para el modelo. Esto mejora la calidad de la representación del texto.\n",
    "\n",
    "- **Categorías codificadas:**  \n",
    "  Se listan las variables categóricas transformadas mediante codificación one-hot. En este caso, corresponden a los diferentes niveles de prioridad del ticket. Cada una se convierte en una columna binaria que indica su presencia.\n",
    "\n",
    "- **Palabras TF-IDF más comunes:**  \n",
    "  Aquí se muestran algunas de las palabras con mayor peso o frecuencia relativa dentro del corpus, después de aplicar la vectorización TF-IDF. Estas palabras representan los términos más relevantes para el conjunto de tickets según su frecuencia y distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb8834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras más comunes según TF-IDF: ['issue' 'assist' 'ive' 'problem' 'product' 'software' 'steps' 'data'\n",
      " 'persists' 'noticed' 'resolve' 'update' 'device' 'help' 'unable' 'tried'\n",
      " 'started' 'need' 'times' 'using']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = preprocessor.named_transformers_['tfidf'].named_steps['tfidf']\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "idf_scores = vectorizer.idf_\n",
    "\n",
    "# Mostrar top 20 palabras con menor IDF (más frecuentes)\n",
    "top_indices = np.argsort(idf_scores)[:20]\n",
    "top_words = feature_names[top_indices]\n",
    "\n",
    "print(\"Palabras más comunes según TF-IDF:\", top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2301e28",
   "metadata": {},
   "source": [
    "Imprimir las 20 palabras más comunes nos permite tener una visión general de qué términos están teniendo mayor peso dentro del corpus de texto. Esta revisión es útil para validar si el proceso de limpieza textual fue efectivo, así como para identificar si las palabras que destacan son realmente relevantes para el análisis. También puede ayudarnos a detectar ruido, redundancias o términos poco informativos que sería conveniente filtrar antes de entrenar un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a742f",
   "metadata": {},
   "source": [
    "Estas palabras reflejan un patrón: \n",
    "- Los clientes reportan problemas técnicos (bugs, errores en software/dispositivos).\n",
    "- Muchos buscan ayuda inmediata (“help”, “resolve”, “unable”, “need”).\n",
    "- Algunos describen acciones previas intentadas (“tried”, “steps”, “started”).\n",
    "\n",
    "Este hallazgo respalda el Insight 3 del EDA: la ausencia de un problema dominante refleja múltiples frentes de mejora operativa.\n",
    "\n",
    "La diversidad de palabras recurrentes sugiere que los clientes enfrentan una amplia gama de inconvenientes, no un único problema repetido. Por tanto, una solución automatizada debe aprender a priorizar casos basándose en estas palabras clave y su contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1c3d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825    issue please assist thanks return thanks under...\n",
       "473     issue please assist protected stringproperty n...\n",
       "3509    encountering software bug whenever try perform...\n",
       "5415    issue please assist please help order fulfillm...\n",
       "5537    issue please assist gnome mmt addressing servi...\n",
       "Name: Ticket Description, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_limpia[\"Ticket Description\"].sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7adfc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825        return  understanding  sharing   forget  i...\n",
       "473        protected stringproperty name productpurcha...\n",
       "3509    encountering software bug whenever try perform...\n",
       "5415         order fulfillment process  patience patie...\n",
       "5537       gnome mmt addressing service found device s...\n",
       "Name: Ticket Description, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_phrases = ['assist', 'please', 'help', 'issue', 'thanks', 'thank', 'sorry' ]\n",
    "def remove_generic_phrases(text):\n",
    "    for phrase in generic_phrases:\n",
    "        text = text.replace(phrase, '')\n",
    "    return text\n",
    "\n",
    "data_limpia[\"Ticket Description\"] = data_limpia[\"Ticket Description\"].apply(remove_generic_phrases)\n",
    "data_limpia[\"Ticket Description\"].sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf565da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palabras con frecuencia 1: 3720\n",
      "Número de palabras con más de 25 caracteres: 162\n",
      "Número de palabras con caracteres no alfabéticos: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "todas_las_palabras = ' '.join(data_limpia[\"Ticket Description\"]).split()\n",
    "\n",
    "# Contar frecuencia de cada palabra\n",
    "word_freq = Counter(todas_las_palabras)\n",
    "\n",
    "# 1. Palabras con frecuencia 1\n",
    "palabras_frec_1 = [word for word, freq in word_freq.items() if freq == 1]\n",
    "\n",
    "# 2. Palabras con más de 25 caracteres\n",
    "palabras_largas = [word for word in word_freq if len(word) > 25]\n",
    "\n",
    "# 3. Palabras que contienen algo no alfabético\n",
    "palabras_no_alfabeticas = [word for word in word_freq if not word.isalpha()]\n",
    "\n",
    "# Imprimir resumen\n",
    "print(f\"Número de palabras con frecuencia 1: {len(palabras_frec_1)}\")\n",
    "print(f\"Número de palabras con más de 25 caracteres: {len(palabras_largas)}\")\n",
    "print(f\"Número de palabras con caracteres no alfabéticos: {len(palabras_no_alfabeticas)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e79cd",
   "metadata": {},
   "source": [
    "Aunque se realizó una limpieza básica del texto (eliminando caracteres no alfabéticos, palabras cortas y stopwords), aún persisten ciertos indicadores de \"ruido\" residual en el corpus. Por ejemplo, se detectaron 3720 palabras con frecuencia 1, lo que puede incluir errores tipográficos, nombres propios poco comunes o tokens irrelevantes. Además, se identificaron 162 palabras con más de 25 caracteres, que podrían ser strings concatenados, identificadores únicos o errores de tokenización. Para reducir aún más el ruido, también se eliminaron frases genéricas frecuentes como \"assist\", \"please\", \"help\", \"thanks\", entre otras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "011cd541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palabras únicas después de limpiar: 2802\n",
      "Número de palabras con más de 25 caracteres después de limpiar: 0\n"
     ]
    }
   ],
   "source": [
    "# Filtrar cada texto eliminando palabras con frecuencia 1 o demasiado largas\n",
    "def limpiar_palabras_residuales(text):\n",
    "    return \" \".join([\n",
    "        word for word in text.split()\n",
    "        if word_freq[word] > 1 and len(word) <= 25\n",
    "    ])\n",
    "\n",
    "# Aplicar la limpieza\n",
    "data_limpia[\"Ticket Description\"] = data_limpia[\"Ticket Description\"].apply(limpiar_palabras_residuales)\n",
    "\n",
    "all_words_cleaned = \" \".join(data_limpia[\"Ticket Description\"]).split()\n",
    "freq_cleaned = Counter(all_words_cleaned)\n",
    "\n",
    "# Estadísticas finales\n",
    "unicas_restantes = len(freq_cleaned)\n",
    "largas_restantes = sum(1 for word in freq_cleaned if len(word) > 25)\n",
    "\n",
    "print(f\"Número de palabras únicas después de limpiar: {unicas_restantes}\")\n",
    "print(f\"Número de palabras con más de 25 caracteres después de limpiar: {largas_restantes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf2a82",
   "metadata": {},
   "source": [
    "Reducir la cantidad de palabras únicas era necesario para eliminar ruido, mejorar la calidad del análisis y optimizar el rendimiento del modelo. Depende del objetivo y del tamaño del corpus, pero en general sí conviene eliminar palabras con frecuencia 1 si representan una proporción significativa (como en este caso: 3720 de más de 5000). Estas palabras suelen ser errores tipográficos, términos irrelevantes o muy específicos, y en modelos basados en bolsa de palabras o TF-IDF aportan muy poco valor o solo introducen ruido. Al limpiar el vocabulario, se obtiene una representación más consistente y útil del texto, lo que facilita el aprendizaje del modelo y reduce la complejidad computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f665c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_11604\\1558628782.py:1: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  data_limpia.to_csv('C:\\CC219-TP-TF-2024-2--CC92\\data/data_limpia2.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "data_limpia.to_csv('C:\\CC219-TP-TF-2024-2--CC92\\data/data_limpia2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
